{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a776b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccde2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53d9c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                             train=True,\n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=80,\n",
    "                                           shuffle=True, )\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transforms.ToTensor())\n",
    "validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=80,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "434cbb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fin_acc(validation_loader, device):\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    data_iter = iter(validation_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    images = images.to(device)\n",
    "    net.eval()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    gt = np.array([classes[labels[j]] for j in range(len(labels))])\n",
    "    pred = np.array([classes[predicted[j]] for j in range(len(labels))])\n",
    "    print(f'Accuracy is {(gt == pred).sum() / len(gt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf49058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3072, out_features=960, bias=True)\n",
       "  (dropout_1): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=960, out_features=720, bias=True)\n",
       "  (dropout_2): Dropout(p=0.3, inplace=False)\n",
       "  (fc3): Linear(in_features=720, out_features=480, bias=True)\n",
       "  (dropout_3): Dropout(p=0.3, inplace=False)\n",
       "  (fc4): Linear(in_features=480, out_features=120, bias=True)\n",
       "  (dropout_4): Dropout(p=0.3, inplace=False)\n",
       "  (fc5): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 8 * hidden_dim)\n",
    "        self.dropout_1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(8 * hidden_dim, 6 * hidden_dim)\n",
    "        self.dropout_2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(6 * hidden_dim, 4*hidden_dim)\n",
    "        self.dropout_3 = nn.Dropout(0.3)\n",
    "        self.fc4 = nn.Linear(4 * hidden_dim, hidden_dim)\n",
    "        self.dropout_4=nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_4(x) \n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_4(x) \n",
    "        x = self.fc5(x)\n",
    "        x = F.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(3072, 120, 10).to(device)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39dc7320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0\n",
      "training_loss:2.30, Accuracy - 9.28\n",
      "validation_loss:2.30, Accuracy - 10.56\n",
      "Epoch - 1\n",
      "training_loss:2.29, Accuracy - 12.06\n",
      "validation_loss:2.27, Accuracy - 11.98\n",
      "Epoch - 2\n",
      "training_loss:2.18, Accuracy - 13.74\n",
      "validation_loss:2.10, Accuracy - 15.07\n",
      "Epoch - 3\n",
      "training_loss:2.08, Accuracy - 15.76\n",
      "validation_loss:2.06, Accuracy - 16.83\n",
      "Epoch - 4\n",
      "training_loss:2.03, Accuracy - 18.36\n",
      "validation_loss:2.00, Accuracy - 20.21\n",
      "Epoch - 5\n",
      "training_loss:1.96, Accuracy - 21.75\n",
      "validation_loss:1.94, Accuracy - 22.54\n",
      "Epoch - 6\n",
      "training_loss:1.91, Accuracy - 23.45\n",
      "validation_loss:1.89, Accuracy - 24.48\n",
      "Epoch - 7\n",
      "training_loss:1.88, Accuracy - 24.96\n",
      "validation_loss:1.86, Accuracy - 25.24\n",
      "Epoch - 8\n",
      "training_loss:1.85, Accuracy - 25.93\n",
      "validation_loss:1.82, Accuracy - 27.06\n",
      "Epoch - 9\n",
      "training_loss:1.82, Accuracy - 26.75\n",
      "validation_loss:1.80, Accuracy - 27.54\n",
      "Epoch - 10\n",
      "training_loss:1.79, Accuracy - 27.77\n",
      "validation_loss:1.76, Accuracy - 28.90\n",
      "Epoch - 11\n",
      "training_loss:1.76, Accuracy - 28.69\n",
      "validation_loss:1.75, Accuracy - 29.26\n",
      "Epoch - 12\n",
      "training_loss:1.74, Accuracy - 29.64\n",
      "validation_loss:1.73, Accuracy - 29.64\n",
      "Epoch - 13\n",
      "training_loss:1.71, Accuracy - 30.15\n",
      "validation_loss:1.70, Accuracy - 30.50\n",
      "Epoch - 14\n",
      "training_loss:1.69, Accuracy - 30.80\n",
      "validation_loss:1.68, Accuracy - 30.79\n",
      "Epoch - 15\n",
      "training_loss:1.67, Accuracy - 31.41\n",
      "validation_loss:1.68, Accuracy - 31.51\n",
      "Epoch - 16\n",
      "training_loss:1.65, Accuracy - 32.07\n",
      "validation_loss:1.67, Accuracy - 31.71\n",
      "Epoch - 17\n",
      "training_loss:1.64, Accuracy - 32.54\n",
      "validation_loss:1.63, Accuracy - 32.94\n",
      "Epoch - 18\n",
      "training_loss:1.62, Accuracy - 33.19\n",
      "validation_loss:1.65, Accuracy - 32.66\n",
      "Epoch - 19\n",
      "training_loss:1.60, Accuracy - 33.67\n",
      "validation_loss:1.60, Accuracy - 34.31\n",
      "Epoch - 20\n",
      "training_loss:1.59, Accuracy - 34.22\n",
      "validation_loss:1.60, Accuracy - 34.24\n",
      "Epoch - 21\n",
      "training_loss:1.57, Accuracy - 34.65\n",
      "validation_loss:1.61, Accuracy - 33.67\n",
      "Epoch - 22\n",
      "training_loss:1.56, Accuracy - 35.17\n",
      "validation_loss:1.62, Accuracy - 34.46\n",
      "Epoch - 23\n",
      "training_loss:1.54, Accuracy - 35.64\n",
      "validation_loss:1.55, Accuracy - 35.26\n",
      "Epoch - 24\n",
      "training_loss:1.53, Accuracy - 36.06\n",
      "validation_loss:1.54, Accuracy - 35.78\n",
      "Epoch - 25\n",
      "training_loss:1.52, Accuracy - 36.40\n",
      "validation_loss:1.55, Accuracy - 35.72\n",
      "Epoch - 26\n",
      "training_loss:1.51, Accuracy - 36.54\n",
      "validation_loss:1.52, Accuracy - 36.35\n",
      "Epoch - 27\n",
      "training_loss:1.50, Accuracy - 37.13\n",
      "validation_loss:1.52, Accuracy - 36.45\n",
      "Epoch - 28\n",
      "training_loss:1.48, Accuracy - 37.36\n",
      "validation_loss:1.53, Accuracy - 36.07\n",
      "Epoch - 29\n",
      "training_loss:1.47, Accuracy - 37.82\n",
      "validation_loss:1.53, Accuracy - 36.31\n",
      "Epoch - 30\n",
      "training_loss:1.46, Accuracy - 38.07\n",
      "validation_loss:1.58, Accuracy - 34.79\n",
      "Epoch - 31\n",
      "training_loss:1.45, Accuracy - 38.14\n",
      "validation_loss:1.48, Accuracy - 37.62\n",
      "Epoch - 32\n",
      "training_loss:1.44, Accuracy - 38.56\n",
      "validation_loss:1.48, Accuracy - 37.75\n",
      "Epoch - 33\n",
      "training_loss:1.43, Accuracy - 38.86\n",
      "validation_loss:1.47, Accuracy - 38.23\n",
      "Epoch - 34\n",
      "training_loss:1.42, Accuracy - 39.30\n",
      "validation_loss:1.47, Accuracy - 37.50\n",
      "Epoch - 35\n",
      "training_loss:1.41, Accuracy - 39.47\n",
      "validation_loss:1.48, Accuracy - 37.65\n",
      "Epoch - 36\n",
      "training_loss:1.40, Accuracy - 39.72\n",
      "validation_loss:1.48, Accuracy - 37.70\n",
      "Epoch - 37\n",
      "training_loss:1.40, Accuracy - 39.85\n",
      "validation_loss:1.45, Accuracy - 38.64\n",
      "Epoch - 38\n",
      "training_loss:1.38, Accuracy - 40.40\n",
      "validation_loss:1.46, Accuracy - 38.27\n",
      "Epoch - 39\n",
      "training_loss:1.37, Accuracy - 40.53\n",
      "validation_loss:1.47, Accuracy - 37.74\n",
      "Epoch - 40\n",
      "training_loss:1.37, Accuracy - 40.79\n",
      "validation_loss:1.47, Accuracy - 38.26\n",
      "Epoch - 41\n",
      "training_loss:1.36, Accuracy - 41.02\n",
      "validation_loss:1.44, Accuracy - 38.82\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "num_epochs = 42\n",
    "loss_history=[] \n",
    "correct_history=[] \n",
    "val_loss_history=[] \n",
    "val_correct_history=[] \n",
    "\n",
    "for e in range(num_epochs): \n",
    "    loss=0.0 \n",
    "    correct=0.0 \n",
    "    val_loss=0.0 \n",
    "    val_correct=0.0 \n",
    "    for inputs, labels in training_loader: \n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device) \n",
    "        outputs = net(inputs) \n",
    "        loss1=criterion(outputs,labels) \n",
    "        optimizer.zero_grad() \n",
    "        loss1.backward() \n",
    "        optimizer.step() \n",
    "        _,preds=torch.max(outputs,1) \n",
    "        loss+=loss1.item() \n",
    "        correct+=torch.sum(preds==labels.data) \n",
    "    else: \n",
    "        with torch.no_grad(): \n",
    "            for val_input,val_labels in validation_loader: \n",
    "                val_input=val_input.to(device) \n",
    "                val_labels=val_labels.to(device) \n",
    "                val_outputs=net(val_input) \n",
    "                val_loss1=criterion(val_outputs,val_labels)  \n",
    "                _,val_preds=torch.max(val_outputs,1) \n",
    "                val_loss+=val_loss1.item() \n",
    "                val_correct+=torch.sum(val_preds==val_labels.data) \n",
    "        epoch_loss=loss/len(training_loader) \n",
    "        epoch_acc=correct.float()/len(training_loader) \n",
    "        loss_history.append(epoch_loss) \n",
    "        correct_history.append(epoch_acc) \n",
    "        val_epoch_loss=val_loss/len(validation_loader) \n",
    "        val_epoch_acc=val_correct.float()/len(validation_loader) \n",
    "        val_loss_history.append(val_epoch_loss) \n",
    "        val_correct_history.append(val_epoch_acc) \n",
    "        print(f'Epoch - {e}')\n",
    "        print('training_loss:{:.2f}, Accuracy - {:.2f}'.format(epoch_loss, epoch_acc.item())) \n",
    "        print('validation_loss:{:.2f}, Accuracy - {:.2f}'.format(val_epoch_loss,val_epoch_acc.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6138c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.5625\n"
     ]
    }
   ],
   "source": [
    "fin_acc(validation_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32b882af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(18, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(36, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc4): Linear(in_features=1152, out_features=576, bias=True)\n",
       "  (dropout_1): Dropout(p=0.3, inplace=False)\n",
       "  (fc5): Linear(in_features=576, out_features=576, bias=True)\n",
       "  (dropout_2): Dropout(p=0.3, inplace=False)\n",
       "  (fc6): Linear(in_features=576, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, chanal, clases):\n",
    "        super().__init__()\n",
    "        self.chanal=chanal\n",
    "        self.conv1 = nn.Conv2d(chanal, chanal*6, chanal, 1,  padding=2)\n",
    "        self.conv2 = nn.Conv2d(chanal*6, chanal*6*2, chanal, 1,padding=1)\n",
    "        self.conv3 = nn.Conv2d(chanal*6*2, chanal*6*2*2, chanal, 1, padding=1)\n",
    "        self.fc4 = nn.Linear(4*4*chanal*6*2*2, 4*4*chanal*6*2 )\n",
    "        self.dropout_1 = nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(4*4*chanal*6*2, 4*4*chanal*6*2)\n",
    "        self.dropout_2 = nn.Dropout(0.3)\n",
    "        self.fc6 = nn.Linear(4*4*chanal*6*2, clases)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=F.relu(self.conv1(x)) \n",
    "        x=F.max_pool2d(x,2,2) \n",
    "        x=F.relu(self.conv2(x)) \n",
    "        x=F.max_pool2d(x,2,2) \n",
    "        x=F.relu(self.conv3(x)) \n",
    "        x=F.max_pool2d(x,2,2) \n",
    "        x=x.view(-1,4*4*self.chanal*6*2*2) \n",
    "        x=F.relu(self.fc4(x)) \n",
    "        x=self.dropout_1(x) \n",
    "        x=self.fc5(x)\n",
    "        x=self.dropout_2(x)\n",
    "        x=self.fc6(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        x=F.relu(self.conv1(x)) \n",
    "        x=F.max_pool2d(x,2,2) \n",
    "        x=F.relu(self.conv2(x)) \n",
    "        x=F.max_pool2d(x,2,2) \n",
    "        x=F.relu(self.conv3(x)) \n",
    "        x=F.max_pool2d(x,2,2) \n",
    "        x=x.view(-1,4*4*self.chanal*6*2*2) \n",
    "        x=F.relu(self.fc4(x)) \n",
    "        x=self.dropout_1(x) \n",
    "        x=self.fc5(x)\n",
    "        x=self.dropout_2(x)\n",
    "        x=self.fc6(x)\n",
    "        x = F.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(3, 10).to(device)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec43a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0\n",
      "training_loss:2.30, Accuracy - 8.85\n",
      "validation_loss:2.30, Accuracy - 9.74\n",
      "Epoch - 1\n",
      "training_loss:2.30, Accuracy - 10.02\n",
      "validation_loss:2.29, Accuracy - 10.97\n",
      "Epoch - 2\n",
      "training_loss:2.27, Accuracy - 12.14\n",
      "validation_loss:2.22, Accuracy - 16.14\n",
      "Epoch - 3\n",
      "training_loss:2.13, Accuracy - 18.57\n",
      "validation_loss:2.03, Accuracy - 21.58\n",
      "Epoch - 4\n",
      "training_loss:2.00, Accuracy - 21.87\n",
      "validation_loss:1.95, Accuracy - 23.83\n",
      "Epoch - 5\n",
      "training_loss:1.93, Accuracy - 23.97\n",
      "validation_loss:1.86, Accuracy - 26.38\n",
      "Epoch - 6\n",
      "training_loss:1.84, Accuracy - 26.88\n",
      "validation_loss:1.76, Accuracy - 29.54\n",
      "Epoch - 7\n",
      "training_loss:1.74, Accuracy - 29.96\n",
      "validation_loss:1.65, Accuracy - 32.73\n",
      "Epoch - 8\n",
      "training_loss:1.65, Accuracy - 32.63\n",
      "validation_loss:1.59, Accuracy - 34.38\n",
      "Epoch - 9\n",
      "training_loss:1.57, Accuracy - 34.58\n",
      "validation_loss:1.53, Accuracy - 36.14\n",
      "Epoch - 10\n",
      "training_loss:1.51, Accuracy - 36.45\n",
      "validation_loss:1.48, Accuracy - 37.34\n",
      "Epoch - 11\n",
      "training_loss:1.46, Accuracy - 38.01\n",
      "validation_loss:1.42, Accuracy - 39.15\n",
      "Epoch - 12\n",
      "training_loss:1.42, Accuracy - 39.45\n",
      "validation_loss:1.41, Accuracy - 39.46\n",
      "Epoch - 13\n",
      "training_loss:1.38, Accuracy - 40.56\n",
      "validation_loss:1.39, Accuracy - 40.54\n",
      "Epoch - 14\n",
      "training_loss:1.34, Accuracy - 41.62\n",
      "validation_loss:1.32, Accuracy - 42.40\n",
      "Epoch - 15\n",
      "training_loss:1.30, Accuracy - 42.86\n",
      "validation_loss:1.29, Accuracy - 43.57\n",
      "Epoch - 16\n",
      "training_loss:1.26, Accuracy - 43.88\n",
      "validation_loss:1.27, Accuracy - 44.02\n",
      "Epoch - 17\n",
      "training_loss:1.23, Accuracy - 45.00\n",
      "validation_loss:1.33, Accuracy - 42.58\n",
      "Epoch - 18\n",
      "training_loss:1.20, Accuracy - 46.19\n",
      "validation_loss:1.22, Accuracy - 45.32\n",
      "Epoch - 19\n",
      "training_loss:1.16, Accuracy - 47.09\n",
      "validation_loss:1.22, Accuracy - 45.78\n",
      "Epoch - 20\n",
      "training_loss:1.13, Accuracy - 47.95\n",
      "validation_loss:1.20, Accuracy - 45.88\n",
      "Epoch - 21\n",
      "training_loss:1.10, Accuracy - 48.70\n",
      "validation_loss:1.13, Accuracy - 47.95\n",
      "Epoch - 22\n",
      "training_loss:1.07, Accuracy - 49.81\n",
      "validation_loss:1.11, Accuracy - 48.57\n",
      "Epoch - 23\n",
      "training_loss:1.05, Accuracy - 50.56\n",
      "validation_loss:1.12, Accuracy - 48.28\n",
      "Epoch - 24\n",
      "training_loss:1.02, Accuracy - 51.21\n",
      "validation_loss:1.09, Accuracy - 49.42\n",
      "Epoch - 25\n",
      "training_loss:1.00, Accuracy - 51.98\n",
      "validation_loss:1.08, Accuracy - 49.77\n",
      "Epoch - 26\n",
      "training_loss:0.97, Accuracy - 52.81\n",
      "validation_loss:1.05, Accuracy - 50.34\n",
      "Epoch - 27\n",
      "training_loss:0.94, Accuracy - 53.43\n",
      "validation_loss:1.05, Accuracy - 50.26\n",
      "Epoch - 28\n",
      "training_loss:0.92, Accuracy - 54.17\n",
      "validation_loss:1.02, Accuracy - 51.00\n",
      "Epoch - 29\n",
      "training_loss:0.89, Accuracy - 54.80\n",
      "validation_loss:1.00, Accuracy - 52.00\n",
      "Epoch - 30\n",
      "training_loss:0.87, Accuracy - 55.51\n",
      "validation_loss:1.02, Accuracy - 52.04\n",
      "Epoch - 31\n",
      "training_loss:0.85, Accuracy - 56.08\n",
      "validation_loss:0.99, Accuracy - 52.55\n",
      "Epoch - 32\n",
      "training_loss:0.83, Accuracy - 56.73\n",
      "validation_loss:1.02, Accuracy - 51.81\n",
      "Epoch - 33\n",
      "training_loss:0.81, Accuracy - 57.45\n",
      "validation_loss:0.97, Accuracy - 53.00\n",
      "Epoch - 34\n",
      "training_loss:0.79, Accuracy - 57.84\n",
      "validation_loss:0.97, Accuracy - 53.34\n",
      "Epoch - 35\n",
      "training_loss:0.76, Accuracy - 58.40\n",
      "validation_loss:0.96, Accuracy - 53.52\n",
      "Epoch - 36\n",
      "training_loss:0.74, Accuracy - 59.05\n",
      "validation_loss:0.97, Accuracy - 53.70\n",
      "Epoch - 37\n",
      "training_loss:0.73, Accuracy - 59.58\n",
      "validation_loss:0.97, Accuracy - 53.46\n",
      "Epoch - 38\n",
      "training_loss:0.71, Accuracy - 60.28\n",
      "validation_loss:0.97, Accuracy - 53.70\n",
      "Epoch - 39\n",
      "training_loss:0.68, Accuracy - 60.80\n",
      "validation_loss:0.98, Accuracy - 53.70\n",
      "Epoch - 40\n",
      "training_loss:0.66, Accuracy - 61.34\n",
      "validation_loss:1.02, Accuracy - 52.56\n",
      "Epoch - 41\n",
      "training_loss:0.65, Accuracy - 61.61\n",
      "validation_loss:0.98, Accuracy - 53.94\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "num_epochs = 42\n",
    "loss_history=[] \n",
    "correct_history=[] \n",
    "val_loss_history=[] \n",
    "val_correct_history=[] \n",
    "\n",
    "for e in range(num_epochs): \n",
    "    loss=0.0 \n",
    "    correct=0.0 \n",
    "    val_loss=0.0 \n",
    "    val_correct=0.0 \n",
    "    for inputs, labels in training_loader: \n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device) \n",
    "        outputs = net(inputs) \n",
    "        loss1=criterion(outputs,labels) \n",
    "        optimizer.zero_grad() \n",
    "        loss1.backward() \n",
    "        optimizer.step() \n",
    "        _,preds=torch.max(outputs,1) \n",
    "        loss+=loss1.item() \n",
    "        correct+=torch.sum(preds==labels.data) \n",
    "    else: \n",
    "        with torch.no_grad(): \n",
    "            for val_input,val_labels in validation_loader: \n",
    "                val_input=val_input.to(device) \n",
    "                val_labels=val_labels.to(device) \n",
    "                val_outputs=net(val_input) \n",
    "                val_loss1=criterion(val_outputs,val_labels)  \n",
    "                _,val_preds=torch.max(val_outputs,1) \n",
    "                val_loss+=val_loss1.item() \n",
    "                val_correct+=torch.sum(val_preds==val_labels.data) \n",
    "        epoch_loss=loss/len(training_loader) \n",
    "        epoch_acc=correct.float()/len(training_loader) \n",
    "        loss_history.append(epoch_loss) \n",
    "        correct_history.append(epoch_acc) \n",
    "        val_epoch_loss=val_loss/len(validation_loader) \n",
    "        val_epoch_acc=val_correct.float()/len(validation_loader) \n",
    "        val_loss_history.append(val_epoch_loss) \n",
    "        val_correct_history.append(val_epoch_acc) \n",
    "        print(f'Epoch - {e}')\n",
    "        print('training_loss:{:.2f}, Accuracy - {:.2f}'.format(epoch_loss, epoch_acc.item())) \n",
    "        print('validation_loss:{:.2f}, Accuracy - {:.2f}'.format(val_epoch_loss,val_epoch_acc.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af1ccb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.725\n"
     ]
    }
   ],
   "source": [
    "fin_acc(validation_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bbf454db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0\n",
      "training_loss:1.70, Accuracy - 30.39\n",
      "validation_loss:1.53, Accuracy - 35.14\n",
      "Epoch - 1\n",
      "training_loss:1.30, Accuracy - 42.20\n",
      "validation_loss:1.20, Accuracy - 45.70\n",
      "Epoch - 2\n",
      "training_loss:1.16, Accuracy - 46.78\n",
      "validation_loss:1.17, Accuracy - 46.73\n",
      "Epoch - 3\n",
      "training_loss:1.07, Accuracy - 49.41\n",
      "validation_loss:1.06, Accuracy - 49.88\n",
      "Epoch - 4\n",
      "training_loss:1.01, Accuracy - 51.50\n",
      "validation_loss:1.04, Accuracy - 50.42\n",
      "Epoch - 5\n",
      "training_loss:0.96, Accuracy - 53.07\n",
      "validation_loss:0.99, Accuracy - 51.64\n",
      "Epoch - 6\n",
      "training_loss:0.91, Accuracy - 54.32\n",
      "validation_loss:0.98, Accuracy - 51.99\n",
      "Epoch - 7\n",
      "training_loss:0.87, Accuracy - 55.43\n",
      "validation_loss:0.96, Accuracy - 53.00\n",
      "Epoch - 8\n",
      "training_loss:0.84, Accuracy - 56.32\n",
      "validation_loss:0.96, Accuracy - 52.89\n",
      "Epoch - 9\n",
      "training_loss:0.81, Accuracy - 57.09\n",
      "validation_loss:0.93, Accuracy - 53.66\n",
      "Epoch - 10\n",
      "training_loss:0.78, Accuracy - 58.08\n",
      "validation_loss:0.91, Accuracy - 54.43\n",
      "Epoch - 11\n",
      "training_loss:0.76, Accuracy - 58.88\n",
      "validation_loss:0.90, Accuracy - 54.90\n",
      "Epoch - 12\n",
      "training_loss:0.73, Accuracy - 59.47\n",
      "validation_loss:0.91, Accuracy - 54.62\n",
      "Epoch - 13\n",
      "training_loss:0.71, Accuracy - 60.00\n",
      "validation_loss:0.88, Accuracy - 55.20\n",
      "Epoch - 14\n",
      "training_loss:0.69, Accuracy - 60.66\n",
      "validation_loss:0.89, Accuracy - 55.47\n",
      "Epoch - 15\n",
      "training_loss:0.67, Accuracy - 61.24\n",
      "validation_loss:0.90, Accuracy - 55.14\n",
      "Epoch - 16\n",
      "training_loss:0.65, Accuracy - 61.70\n",
      "validation_loss:0.88, Accuracy - 55.60\n",
      "Epoch - 17\n",
      "training_loss:0.63, Accuracy - 62.41\n",
      "validation_loss:0.88, Accuracy - 56.10\n",
      "Epoch - 18\n",
      "training_loss:0.61, Accuracy - 62.95\n",
      "validation_loss:0.89, Accuracy - 55.71\n",
      "Epoch - 19\n",
      "training_loss:0.59, Accuracy - 63.29\n",
      "validation_loss:0.87, Accuracy - 56.53\n",
      "Epoch - 20\n",
      "training_loss:0.57, Accuracy - 63.91\n",
      "validation_loss:0.89, Accuracy - 56.26\n",
      "Epoch - 21\n",
      "training_loss:0.56, Accuracy - 64.42\n",
      "validation_loss:0.89, Accuracy - 56.19\n",
      "Epoch - 22\n",
      "training_loss:0.54, Accuracy - 64.92\n",
      "validation_loss:0.89, Accuracy - 56.61\n",
      "Epoch - 23\n",
      "training_loss:0.52, Accuracy - 65.47\n",
      "validation_loss:0.87, Accuracy - 56.46\n",
      "Epoch - 24\n",
      "training_loss:0.51, Accuracy - 65.72\n",
      "validation_loss:0.91, Accuracy - 56.34\n",
      "Epoch - 25\n",
      "training_loss:0.50, Accuracy - 66.19\n",
      "validation_loss:0.89, Accuracy - 56.54\n",
      "Epoch - 26\n",
      "training_loss:0.48, Accuracy - 66.46\n",
      "validation_loss:0.90, Accuracy - 56.26\n",
      "Epoch - 27\n",
      "training_loss:0.47, Accuracy - 66.97\n",
      "validation_loss:0.90, Accuracy - 56.66\n",
      "Epoch - 28\n",
      "training_loss:0.45, Accuracy - 67.35\n",
      "validation_loss:0.92, Accuracy - 56.19\n",
      "Epoch - 29\n",
      "training_loss:0.44, Accuracy - 67.64\n",
      "validation_loss:0.92, Accuracy - 56.63\n",
      "Epoch - 30\n",
      "training_loss:0.43, Accuracy - 68.11\n",
      "validation_loss:0.93, Accuracy - 56.32\n",
      "Epoch - 31\n",
      "training_loss:0.41, Accuracy - 68.36\n",
      "validation_loss:0.91, Accuracy - 56.66\n",
      "Epoch - 32\n",
      "training_loss:0.40, Accuracy - 68.82\n",
      "validation_loss:0.94, Accuracy - 56.70\n",
      "Epoch - 33\n",
      "training_loss:0.39, Accuracy - 69.22\n",
      "validation_loss:0.97, Accuracy - 56.50\n",
      "Epoch - 34\n",
      "training_loss:0.38, Accuracy - 69.52\n",
      "validation_loss:0.95, Accuracy - 56.84\n",
      "Epoch - 35\n",
      "training_loss:0.36, Accuracy - 69.89\n",
      "validation_loss:0.98, Accuracy - 56.42\n",
      "Epoch - 36\n",
      "training_loss:0.35, Accuracy - 70.01\n",
      "validation_loss:0.98, Accuracy - 56.69\n",
      "Epoch - 37\n",
      "training_loss:0.34, Accuracy - 70.44\n",
      "validation_loss:0.99, Accuracy - 56.58\n",
      "Epoch - 38\n",
      "training_loss:0.33, Accuracy - 70.80\n",
      "validation_loss:1.00, Accuracy - 56.67\n",
      "Epoch - 39\n",
      "training_loss:0.32, Accuracy - 71.06\n",
      "validation_loss:1.02, Accuracy - 56.74\n",
      "Epoch - 40\n",
      "training_loss:0.31, Accuracy - 71.24\n",
      "validation_loss:1.04, Accuracy - 56.43\n",
      "Epoch - 41\n",
      "training_loss:0.30, Accuracy - 71.49\n",
      "validation_loss:1.03, Accuracy - 56.94\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.01)\n",
    "num_epochs = 42\n",
    "loss_history=[] \n",
    "correct_history=[] \n",
    "val_loss_history=[] \n",
    "val_correct_history=[] \n",
    "\n",
    "for e in range(num_epochs): \n",
    "    loss=0.0 \n",
    "    correct=0.0 \n",
    "    val_loss=0.0 \n",
    "    val_correct=0.0 \n",
    "    for inputs, labels in training_loader: \n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device) \n",
    "        outputs = net(inputs) \n",
    "        loss1=criterion(outputs,labels) \n",
    "        optimizer.zero_grad() \n",
    "        loss1.backward() \n",
    "        optimizer.step() \n",
    "        _,preds=torch.max(outputs,1) \n",
    "        loss+=loss1.item() \n",
    "        correct+=torch.sum(preds==labels.data) \n",
    "    else: \n",
    "        with torch.no_grad(): \n",
    "            for val_input,val_labels in validation_loader: \n",
    "                val_input=val_input.to(device) \n",
    "                val_labels=val_labels.to(device) \n",
    "                val_outputs=net(val_input) \n",
    "                val_loss1=criterion(val_outputs,val_labels)  \n",
    "                _,val_preds=torch.max(val_outputs,1) \n",
    "                val_loss+=val_loss1.item() \n",
    "                val_correct+=torch.sum(val_preds==val_labels.data) \n",
    "        epoch_loss=loss/len(training_loader) \n",
    "        epoch_acc=correct.float()/len(training_loader) \n",
    "        loss_history.append(epoch_loss) \n",
    "        correct_history.append(epoch_acc) \n",
    "        val_epoch_loss=val_loss/len(validation_loader) \n",
    "        val_epoch_acc=val_correct.float()/len(validation_loader) \n",
    "        val_loss_history.append(val_epoch_loss) \n",
    "        val_correct_history.append(val_epoch_acc) \n",
    "        print(f'Epoch - {e}')\n",
    "        print('training_loss:{:.2f}, Accuracy - {:.2f}'.format(epoch_loss, epoch_acc.item())) \n",
    "        print('validation_loss:{:.2f}, Accuracy - {:.2f}'.format(val_epoch_loss,val_epoch_acc.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8cde0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7375\n"
     ]
    }
   ],
   "source": [
    "fin_acc(validation_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff044b7a",
   "metadata": {},
   "source": [
    "При использовании cnn слоев обучение модели ускорилось при этом вычислительной сложности сети стала ниже чем в случае полносвязной сетью так как у сверток \n",
    "  1) весов намного меньше \n",
    "  2) более гибкая связь (не все входы в равной степени влиют на выходы).  \n",
    "  \n",
    "Использование Adgard из семейства адаптированых градиентных спусков так же позволило увеличить скорость обучения на начальных эпохах за счет меньшего обновления весов которые ранее часто обновлялись.  \n",
    "Так же использование дропаут (позволяет создать своего рода усредненый \"\"ансабль\"\" сетей за счет того что не все нейроны в равной степени задействованны при каждой эпохе) позволило стабилизировать обучение и уменьшить переобучение.\n",
    "\n",
    "Цель по метрике 5 из 8 0.625 достигнута. Сверточная сеть показала 0.73 (ее можно еще дообучать а в случае адгард стоит увеличить количество нейронов в дропаут слоях и возможно довать L2 регуляризацию) В случае сетью с прямым распостранение тоже стоит продолжить обучение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
