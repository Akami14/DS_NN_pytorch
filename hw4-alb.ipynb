{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e459c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:54:42.508321Z",
     "iopub.status.busy": "2024-02-06T09:54:42.507943Z",
     "iopub.status.idle": "2024-02-06T09:54:42.513994Z",
     "shell.execute_reply": "2024-02-06T09:54:42.513013Z",
     "shell.execute_reply.started": "2024-02-06T09:54:42.508295Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5df525",
   "metadata": {},
   "source": [
    "## Обучите CNN  с аугментацией данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb38b15f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:53:39.441308Z",
     "iopub.status.busy": "2024-02-06T09:53:39.440956Z",
     "iopub.status.idle": "2024-02-06T09:53:52.506303Z",
     "shell.execute_reply": "2024-02-06T09:53:52.505179Z",
     "shell.execute_reply.started": "2024-02-06T09:53:39.441277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c735307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:54:24.067183Z",
     "iopub.status.busy": "2024-02-06T09:54:24.066722Z",
     "iopub.status.idle": "2024-02-06T09:54:36.171215Z",
     "shell.execute_reply": "2024-02-06T09:54:36.170077Z",
     "shell.execute_reply.started": "2024-02-06T09:54:24.067135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.11.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.22.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.9.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (9.5.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2023.12.9)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.16.1->albumentations) (3.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c59efd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:54:42.572449Z",
     "iopub.status.busy": "2024-02-06T09:54:42.572144Z",
     "iopub.status.idle": "2024-02-06T09:54:42.580891Z",
     "shell.execute_reply": "2024-02-06T09:54:42.580045Z",
     "shell.execute_reply.started": "2024-02-06T09:54:42.572423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5441f780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:54:59.334846Z",
     "iopub.status.busy": "2024-02-06T09:54:59.334120Z",
     "iopub.status.idle": "2024-02-06T09:54:59.339962Z",
     "shell.execute_reply": "2024-02-06T09:54:59.338875Z",
     "shell.execute_reply.started": "2024-02-06T09:54:59.334813Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_valid_split(Xt):\n",
    "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "800e7280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:54:46.767864Z",
     "iopub.status.busy": "2024-02-06T09:54:46.767474Z",
     "iopub.status.idle": "2024-02-06T09:54:52.111847Z",
     "shell.execute_reply": "2024-02-06T09:54:52.110870Z",
     "shell.execute_reply.started": "2024-02-06T09:54:46.767819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:02<00:00, 74227968.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-100-python.tar.gz to data/\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR100(root='data/', train=True, download=True)\n",
    "\n",
    "\n",
    "class MyOwnCifar(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, init_dataset, transform=None):\n",
    "        self._base_dataset = init_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self._base_dataset[idx][0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self._base_dataset[idx][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe76d2",
   "metadata": {},
   "source": [
    "## Аргументация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a9b8ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:54:52.114566Z",
     "iopub.status.busy": "2024-02-06T09:54:52.113739Z",
     "iopub.status.idle": "2024-02-06T09:54:52.688666Z",
     "shell.execute_reply": "2024-02-06T09:54:52.687397Z",
     "shell.execute_reply.started": "2024-02-06T09:54:52.114526Z"
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "#from albumentations.pytorch import ToTensor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "alb_transform = alb.Compose(\n",
    "    [\n",
    "        #alb.Resize(height=256, width=256),\n",
    "        #alb.RandomCrop(height=224, width=224),\n",
    "        #alb.HorizontalFlip(p=0.25, ),\n",
    "        #alb.\n",
    "        #alb.SmallestMaxSize(max_size=160,always_apply=False),\n",
    "        alb.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=1, always_apply=False),\n",
    "        #alb.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5, always_apply=False),\n",
    "        alb.RandomBrightnessContrast(p=0.15, always_apply=False),\n",
    "        #alb.OneOf([\n",
    "         #   alb.MotionBlur(p=1),\n",
    "         #   alb.OpticalDistortion(p=1),\n",
    "         #   alb.GaussNoise(p=1)\n",
    "        #], p=1),\n",
    "        alb.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                      std=(0.229, 0.224, 0.225)),\n",
    "         #ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62a13c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:55:04.104316Z",
     "iopub.status.busy": "2024-02-06T09:55:04.103948Z",
     "iopub.status.idle": "2024-02-06T09:55:06.513556Z",
     "shell.execute_reply": "2024-02-06T09:55:06.512784Z",
     "shell.execute_reply.started": "2024-02-06T09:55:04.104284Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([alb_transform,\n",
    "                                    #transforms.RandomCrop(224, padding=4),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225])])\n",
    "#mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "valid_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=700,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=700,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce8c3f",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948a30c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:55:08.217500Z",
     "iopub.status.busy": "2024-02-06T09:55:08.217090Z",
     "iopub.status.idle": "2024-02-06T09:55:09.356808Z",
     "shell.execute_reply": "2024-02-06T09:55:09.355926Z",
     "shell.execute_reply.started": "2024-02-06T09:55:08.217453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Dropout-1            [-1, 3, 32, 32]               0\n",
      "       BatchNorm2d-2            [-1, 3, 32, 32]               6\n",
      "            Conv2d-3           [-1, 30, 32, 32]             840\n",
      "       BatchNorm2d-4           [-1, 30, 32, 32]              60\n",
      "            Conv2d-5           [-1, 64, 32, 32]          17,344\n",
      "           Dropout-6           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
      "            Conv2d-8          [-1, 128, 32, 32]          73,856\n",
      "           Dropout-9          [-1, 128, 32, 32]               0\n",
      "      BatchNorm2d-10          [-1, 128, 16, 16]             256\n",
      "           Conv2d-11          [-1, 128, 14, 14]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
      "           Conv2d-13          [-1, 256, 12, 12]         295,168\n",
      "      BatchNorm2d-14            [-1, 256, 6, 6]             512\n",
      "           Conv2d-15            [-1, 256, 4, 4]         590,080\n",
      "      BatchNorm2d-16            [-1, 256, 4, 4]             512\n",
      "           Conv2d-17            [-1, 512, 2, 2]       1,180,160\n",
      "      BatchNorm2d-18            [-1, 512, 2, 2]           1,024\n",
      "           Linear-19                 [-1, 1024]       2,098,176\n",
      "          Dropout-20                 [-1, 1024]               0\n",
      "           Linear-21                  [-1, 512]         524,800\n",
      "          Dropout-22                  [-1, 512]               0\n",
      "           Linear-23                  [-1, 100]          51,300\n",
      "================================================================\n",
      "Total params: 4,982,062\n",
      "Trainable params: 4,982,062\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.12\n",
      "Params size (MB): 19.01\n",
      "Estimated Total Size (MB): 24.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net_CCN_5(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net_CCN_5, self).__init__()\n",
    "\n",
    "        self.dp1 = nn.Dropout(0.3)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(3)\n",
    "        self.conv1 = torch.nn.Conv2d(3, 30, 3)#32\n",
    "\n",
    "        self.bn2 = torch.nn.BatchNorm2d(30)\n",
    "        self.conv2 = torch.nn.Conv2d(30, 64, 3) #32\n",
    "        self.dp2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.bn3= torch.nn.BatchNorm2d(64)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 128, 3) #32 вход\n",
    "        self.dp3 = nn.Dropout(0.2)\n",
    "        #polling запулингировали 16\n",
    "\n",
    "        self.bn4 = torch.nn.BatchNorm2d(128)\n",
    "        self.conv4 = torch.nn.Conv2d(128, 128, 3) #16 в 14\n",
    "        self.dp4 = nn.Dropout(0.2)\n",
    "\n",
    "        self.bn5= torch.nn.BatchNorm2d(128)\n",
    "        self.conv5 = torch.nn.Conv2d(128, 256, 3) #14 в 12\n",
    "        self.dp5 = nn.Dropout(0.2)\n",
    "\n",
    "        #polling #из 12 в 6\n",
    "\n",
    "        self.bn6 = torch.nn.BatchNorm2d(256)\n",
    "        self.conv6 = torch.nn.Conv2d(256, 256, 3) #из 6 в 4\n",
    "        self.dp6 = nn.Dropout(0.1)\n",
    "\n",
    "        self.bn7 = torch.nn.BatchNorm2d(256)\n",
    "        self.conv7 = torch.nn.Conv2d(256, 512, 3) # 2\n",
    "        #self.fl = torch.nn.Flatten(2)\n",
    "        self.dp7 = nn.Dropout(0.1)\n",
    "\n",
    "        self.bn8 = torch.nn.BatchNorm2d(512)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(2048, 1024) #256 на 3 на 3\n",
    "        self.dp_fc1 = nn.Dropout(0.3)\n",
    "        self.fc2 = torch.nn.Linear(1024, 512)\n",
    "        self.dp_fc2 = nn.Dropout(0.2)\n",
    "        self.out = torch.nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dp1(x)\n",
    "        x = self.bn1(x) # 32 на 32\n",
    "        x = torch.nn.functional.pad(x, (1, 1, 1, 1), mode='reflect')\n",
    "        x = self.conv1(x) # 32 на 32 падинг 1\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = torch.nn.functional.pad(x, (1, 1, 1, 1), mode='reflect')\n",
    "        x = self.conv2(x) #30 на 30\n",
    "        x = self.dp2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.bn3(x)\n",
    "        x = torch.nn.functional.pad(x, (1, 1, 1, 1), mode='reflect')\n",
    "        x = self.conv3(x) #28 на 28\n",
    "        x = self.dp3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.avg_pool2d(x,2,stride=2) #14 на 14\n",
    "\n",
    "        x = self.bn4(x) #14 на 14\n",
    "        x = self.conv4(x) #12 на 12\n",
    "        #x = self.dp4(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.bn5(x)\n",
    "        x = self.conv5(x) #\n",
    "        #x = self.dp5(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.avg_pool2d(x,2,stride=2)\n",
    "\n",
    "        x = self.bn6(x)\n",
    "        x = self.conv6(x)\n",
    "        #x = self.dp6(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.bn7(x)\n",
    "        x = self.conv7(x)\n",
    "        #x = self.dp7(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.fl(x)\n",
    "        x = self.bn8(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dp_fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.dp_fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self.out(x)\n",
    "\n",
    "net = Net_CCN_5().to(device)\n",
    "#print(net)\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(net, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf20fda5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:55:12.365559Z",
     "iopub.status.busy": "2024-02-06T09:55:12.365127Z",
     "iopub.status.idle": "2024-02-06T09:55:12.371144Z",
     "shell.execute_reply": "2024-02-06T09:55:12.369909Z",
     "shell.execute_reply.started": "2024-02-06T09:55:12.365524Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0710f5",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76a6f2eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:55:13.213265Z",
     "iopub.status.busy": "2024-02-06T09:55:13.212536Z",
     "iopub.status.idle": "2024-02-06T09:55:13.218252Z",
     "shell.execute_reply": "2024-02-06T09:55:13.217184Z",
     "shell.execute_reply.started": "2024-02-06T09:55:13.213231Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.NAdam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf2f284b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T09:55:14.907283Z",
     "iopub.status.busy": "2024-02-06T09:55:14.906322Z",
     "iopub.status.idle": "2024-02-06T09:57:54.941346Z",
     "shell.execute_reply": "2024-02-06T09:57:54.939938Z",
     "shell.execute_reply.started": "2024-02-06T09:55:14.907236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]. Step [1/68]. Loss: 0.0066. Acc: 1.1429. Test acc: 1.160\n",
      "Epoch [2/100]. Step [1/68]. Loss: 0.0063. Acc: 5.1429. Test acc: 1.920\n",
      "Epoch [3/100]. Step [1/68]. Loss: 0.0062. Acc: 5.5714. Test acc: 1.280\n",
      "Epoch [4/100]. Step [1/68]. Loss: 0.0060. Acc: 6.4286. Test acc: 4.560\n",
      "Epoch [5/100]. Step [1/68]. Loss: 0.0059. Acc: 5.8571. Test acc: 7.680\n",
      "Epoch [6/100]. Step [1/68]. Loss: 0.0059. Acc: 8.2857. Test acc: 6.680\n",
      "Epoch [7/100]. Step [1/68]. Loss: 0.0056. Acc: 8.8571. Test acc: 12.360\n",
      "Epoch [8/100]. Step [1/68]. Loss: 0.0055. Acc: 11.4286. Test acc: 13.040\n",
      "Epoch [9/100]. Step [1/68]. Loss: 0.0051. Acc: 13.7143. Test acc: 12.360\n",
      "Epoch [10/100]. Step [1/68]. Loss: 0.0051. Acc: 14.1429. Test acc: 11.480\n",
      "Epoch [11/100]. Step [1/68]. Loss: 0.0048. Acc: 15.2857. Test acc: 15.080\n",
      "Epoch [12/100]. Step [1/68]. Loss: 0.0049. Acc: 17.5714. Test acc: 17.080\n",
      "Epoch [13/100]. Step [1/68]. Loss: 0.0047. Acc: 17.4286. Test acc: 15.960\n",
      "Epoch [14/100]. Step [1/68]. Loss: 0.0043. Acc: 22.4286. Test acc: 16.680\n",
      "Epoch [15/100]. Step [1/68]. Loss: 0.0041. Acc: 25.7143. Test acc: 24.640\n",
      "Epoch [16/100]. Step [1/68]. Loss: 0.0043. Acc: 23.7143. Test acc: 23.440\n",
      "Epoch [17/100]. Step [1/68]. Loss: 0.0034. Acc: 34.8571. Test acc: 29.480\n",
      "Epoch [18/100]. Step [1/68]. Loss: 0.0035. Acc: 35.2857. Test acc: 31.920\n",
      "Epoch [19/100]. Step [1/68]. Loss: 0.0033. Acc: 37.7143. Test acc: 40.560\n",
      "Epoch [20/100]. Step [1/68]. Loss: 0.0027. Acc: 45.4286. Test acc: 36.200\n",
      "Epoch [21/100]. Step [1/68]. Loss: 0.0025. Acc: 50.2857. Test acc: 45.880\n",
      "Epoch [22/100]. Step [1/68]. Loss: 0.0020. Acc: 61.1429. Test acc: 42.840\n",
      "Epoch [23/100]. Step [1/68]. Loss: 0.0019. Acc: 60.0000. Test acc: 55.320\n",
      "Epoch [24/100]. Step [1/68]. Loss: 0.0015. Acc: 67.7143. Test acc: 61.600\n",
      "Epoch [25/100]. Step [1/68]. Loss: 0.0013. Acc: 74.2857. Test acc: 53.640\n",
      "Epoch [26/100]. Step [1/68]. Loss: 0.0009. Acc: 83.4286. Test acc: 60.760\n",
      "Epoch [27/100]. Step [1/68]. Loss: 0.0008. Acc: 86.5714. Test acc: 72.880\n",
      "Epoch [28/100]. Step [1/68]. Loss: 0.0005. Acc: 91.1429. Test acc: 74.280\n",
      "Epoch [29/100]. Step [1/68]. Loss: 0.0004. Acc: 93.7143. Test acc: 74.960\n",
      "Epoch [30/100]. Step [1/68]. Loss: 0.0003. Acc: 94.2857. Test acc: 78.400\n",
      "Epoch [31/100]. Step [1/68]. Loss: 0.0002. Acc: 96.0000. Test acc: 82.480\n",
      "Epoch [32/100]. Step [1/68]. Loss: 0.0002. Acc: 97.0000. Test acc: 77.760\n",
      "Epoch [33/100]. Step [1/68]. Loss: 0.0002. Acc: 96.2857. Test acc: 81.920\n",
      "Epoch [34/100]. Step [1/68]. Loss: 0.0002. Acc: 97.1429. Test acc: 83.800\n",
      "Epoch [35/100]. Step [1/68]. Loss: 0.0001. Acc: 98.5714. Test acc: 82.280\n",
      "Epoch [36/100]. Step [1/68]. Loss: 0.0001. Acc: 98.1429. Test acc: 83.120\n",
      "Epoch [37/100]. Step [1/68]. Loss: 0.0001. Acc: 99.0000. Test acc: 84.480\n",
      "Epoch [38/100]. Step [1/68]. Loss: 0.0001. Acc: 99.1429. Test acc: 86.600\n",
      "Epoch [39/100]. Step [1/68]. Loss: 0.0001. Acc: 99.7143. Test acc: 80.680\n",
      "Epoch [40/100]. Step [1/68]. Loss: 0.0001. Acc: 99.4286. Test acc: 85.800\n",
      "Epoch [41/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 86.400\n",
      "Epoch [42/100]. Step [1/68]. Loss: 0.0000. Acc: 99.5714. Test acc: 84.080\n",
      "Epoch [43/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 85.040\n",
      "Epoch [44/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 86.240\n",
      "Epoch [45/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 86.080\n",
      "Epoch [46/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 86.120\n",
      "Epoch [47/100]. Step [1/68]. Loss: 0.0000. Acc: 99.5714. Test acc: 84.840\n",
      "Epoch [48/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 86.000\n",
      "Epoch [49/100]. Step [1/68]. Loss: 0.0000. Acc: 99.2857. Test acc: 86.240\n",
      "Epoch [50/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 85.800\n",
      "Epoch [51/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 84.800\n",
      "Epoch [52/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 84.600\n",
      "Epoch [53/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 84.440\n",
      "Epoch [54/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 85.320\n",
      "Epoch [55/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 84.200\n",
      "Epoch [56/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 84.880\n",
      "Epoch [57/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 84.640\n",
      "Epoch [58/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 85.720\n",
      "Epoch [59/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 82.320\n",
      "Epoch [60/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 83.720\n",
      "Epoch [61/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 83.640\n",
      "Epoch [62/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 85.000\n",
      "Epoch [63/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 85.400\n",
      "Epoch [64/100]. Step [1/68]. Loss: 0.0002. Acc: 98.0000. Test acc: 80.880\n",
      "Epoch [65/100]. Step [1/68]. Loss: 0.0039. Acc: 47.2857. Test acc: 11.320\n",
      "Epoch [66/100]. Step [1/68]. Loss: 0.0045. Acc: 25.4286. Test acc: 28.680\n",
      "Epoch [67/100]. Step [1/68]. Loss: 0.0032. Acc: 44.8571. Test acc: 47.840\n",
      "Epoch [68/100]. Step [1/68]. Loss: 0.0018. Acc: 64.2857. Test acc: 63.640\n",
      "Epoch [69/100]. Step [1/68]. Loss: 0.0010. Acc: 79.4286. Test acc: 71.480\n",
      "Epoch [70/100]. Step [1/68]. Loss: 0.0004. Acc: 92.4286. Test acc: 83.960\n",
      "Epoch [71/100]. Step [1/68]. Loss: 0.0003. Acc: 96.7143. Test acc: 89.800\n",
      "Epoch [72/100]. Step [1/68]. Loss: 0.0002. Acc: 97.7143. Test acc: 91.160\n",
      "Epoch [73/100]. Step [1/68]. Loss: 0.0001. Acc: 98.7143. Test acc: 88.160\n",
      "Epoch [74/100]. Step [1/68]. Loss: 0.0001. Acc: 98.1429. Test acc: 89.040\n",
      "Epoch [75/100]. Step [1/68]. Loss: 0.0001. Acc: 99.2857. Test acc: 91.280\n",
      "Epoch [76/100]. Step [1/68]. Loss: 0.0001. Acc: 99.2857. Test acc: 92.160\n",
      "Epoch [77/100]. Step [1/68]. Loss: 0.0000. Acc: 99.2857. Test acc: 90.320\n",
      "Epoch [78/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 89.360\n",
      "Epoch [79/100]. Step [1/68]. Loss: 0.0001. Acc: 99.2857. Test acc: 90.840\n",
      "Epoch [80/100]. Step [1/68]. Loss: 0.0000. Acc: 99.1429. Test acc: 91.320\n",
      "Epoch [81/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 90.760\n",
      "Epoch [82/100]. Step [1/68]. Loss: 0.0000. Acc: 99.5714. Test acc: 90.320\n",
      "Epoch [83/100]. Step [1/68]. Loss: 0.0001. Acc: 99.1429. Test acc: 87.600\n",
      "Epoch [84/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 90.000\n",
      "Epoch [85/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 90.680\n",
      "Epoch [86/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 89.320\n",
      "Epoch [87/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 89.320\n",
      "Epoch [88/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 89.000\n",
      "Epoch [89/100]. Step [1/68]. Loss: 0.0000. Acc: 99.1429. Test acc: 89.480\n",
      "Epoch [90/100]. Step [1/68]. Loss: 0.0000. Acc: 99.1429. Test acc: 89.280\n",
      "Epoch [91/100]. Step [1/68]. Loss: 0.0000. Acc: 99.5714. Test acc: 90.240\n",
      "Epoch [92/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 89.480\n",
      "Epoch [93/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 89.440\n",
      "Epoch [94/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 90.520\n",
      "Epoch [95/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 89.800\n",
      "Epoch [96/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 89.560\n",
      "Epoch [97/100]. Step [1/68]. Loss: 0.0000. Acc: 99.7143. Test acc: 89.760\n",
      "Epoch [98/100]. Step [1/68]. Loss: 0.0000. Acc: 99.8571. Test acc: 89.960\n",
      "Epoch [99/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 90.360\n",
      "Epoch [100/100]. Step [1/68]. Loss: 0.0000. Acc: 100.0000. Test acc: 90.480\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            net.eval()\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.4f}. ' \\\n",
    "                  f'Acc: {(running_right / running_items)*100:.4f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "\n",
    "                test_outputs = net(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "\n",
    "            print(f'Test acc: {(test_running_right / test_running_total)*100:.3f}')\n",
    "\n",
    "        net.train()\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34c2ac66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T10:05:23.061646Z",
     "iopub.status.busy": "2024-02-06T10:05:23.061188Z",
     "iopub.status.idle": "2024-02-06T10:05:23.652575Z",
     "shell.execute_reply": "2024-02-06T10:05:23.651498Z",
     "shell.execute_reply.started": "2024-02-06T10:05:23.061608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final Test Accuracy of the model: 90.72 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('The final Test Accuracy of the model: {} %'.format((correct / total) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02afa1",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218e854",
   "metadata": {},
   "source": [
    "Аргументация в целом позволяет снизить переобучение, но необходимо правильная, оптимальная настройков параметров   \n",
    "если параметры аргументации будут генерировать изображения которые мало похожи на изображения в тестовой выборке пользы от аргументации не будет.  \n",
    "В моем случае аргументация вместе с подбором % dropout и скорости обучения так же позволила ускорить обучение и снизить переобучение.  \n",
    "Для данной задачи достаточно 40-50 эпох обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63628358",
   "metadata": {},
   "source": [
    "Созданая модель хоть и приходит к оптимуму за большее количество эпох по тренировочной выборке, \n",
    "но приходить туда все таки быстрее по времени за счет меньшего количества параметров сети которые необходимо пересчитывать (веса)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
